{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0920a7a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from transformers import pipeline\n",
    "from PIL import Image\n",
    "from src.pipeline.feature_extractor import FeatureExtractor\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b2b41137",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The image processor of type `Mask2FormerImageProcessor` is now loaded as a fast processor by default, even if the model checkpoint was saved with a slow processor. This is a breaking change and may produce slightly different outputs. To continue using the slow processor, instantiate this class with `use_fast=False`. \n",
      "Loading weights: 100%|██████████| 782/782 [00:00<00:00, 1813.99it/s, Materializing param=model.transformer_module.queries_features.weight]                                                       \n"
     ]
    }
   ],
   "source": [
    "extractor = FeatureExtractor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "491e4592",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = Image.open(\"Tokyo_Skytree_2014.jpg\")\n",
    "img_input = extractor.mask_processor(img, return_tensors=\"pt\")\n",
    "with torch.no_grad():\n",
    "    out = extractor(img_input, [img], [img.size[::-1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f11e3808",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_img = [Image.fromarray(mask).convert(\"RGB\") for mask in out[\"masks\"][0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "20417f3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading weights: 100%|██████████| 471/471 [00:00<00:00, 2015.24it/s, Materializing param=model.vision_model.post_layernorm.weight]                      \n"
     ]
    }
   ],
   "source": [
    "smol_pipe = pipeline(\"image-text-to-text\", model=\"HuggingFaceTB/SmolVLM-256M-Instruct\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "3fe06253",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"You are an image annotation expert.\n",
    "You will be given an original image and several images of its segmentation part along with labels.\n",
    "By matching the original image and the segment maps, your task is to assign a probability score to each segment label of how much it contribute to the original image representation.\n",
    "The total probability score of all segments must be 1.\n",
    "\n",
    "example output:\n",
    "```json\n",
    "{\n",
    "    \"segment_scores\": [\n",
    "        {\n",
    "            \"building\": 0.2,\n",
    "            \"tower\": 0.7,\n",
    "            \"sky\": 0.1\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "```\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "4b521fc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['building', 'sky', 'tower']"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out[\"labels\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "57b4870a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=256) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'input_text': [{'role': 'user',\n",
       "    'content': [{'type': 'text',\n",
       "      'text': 'which one of the images segmentation below the most representing the landmark?'},\n",
       "     {'type': 'image',\n",
       "      'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=960x1471>},\n",
       "     {'type': 'text', 'text': 'original image'},\n",
       "     {'type': 'image',\n",
       "      'image': <PIL.Image.Image image mode=RGB size=960x1471>},\n",
       "     {'type': 'text', 'text': 'mask label: building'},\n",
       "     {'type': 'image',\n",
       "      'image': <PIL.Image.Image image mode=RGB size=960x1471>},\n",
       "     {'type': 'text', 'text': 'mask label: sky'},\n",
       "     {'type': 'image',\n",
       "      'image': <PIL.Image.Image image mode=RGB size=960x1471>},\n",
       "     {'type': 'text', 'text': 'mask label: tower'}]}],\n",
       "  'generated_text': ' The black background is a white silhouette of a gun.'}]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages = [\n",
    "    # {\n",
    "    #     \"role\": \"system\",\n",
    "    #     \"content\": prompt\n",
    "    # },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\"type\": \"text\", \"text\": \"which one of the images segmentation below the most representing the landmark?\"},\n",
    "            {\"type\": \"image\", \"image\": img},\n",
    "            {\"type\": \"text\", \"text\": \"original image\"},\n",
    "            {\"type\": \"image\", \"image\": mask_img[0]},\n",
    "            {\"type\": \"text\", \"text\": f\"mask label: {out[\"labels\"][0][0]}\"},\n",
    "            {\"type\": \"image\", \"image\": mask_img[1]},\n",
    "            {\"type\": \"text\", \"text\": f\"mask label: {out[\"labels\"][0][1]}\"},\n",
    "            {\"type\": \"image\", \"image\": mask_img[2]},\n",
    "            {\"type\": \"text\", \"text\": f\"mask label: {out[\"labels\"][0][2]}\"},\n",
    "        ]\n",
    "    }\n",
    "]\n",
    "smol_pipe.model.generation_config.max_length = None\n",
    "smol_out = smol_pipe(text=messages, return_full_text=False, max_length=256)\n",
    "smol_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "739c7b65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'input_text': [{'role': 'user',\n",
       "    'content': [{'type': 'text',\n",
       "      'text': 'which one of the images segmentation below the most representing the landmark?'},\n",
       "     {'type': 'image',\n",
       "      'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=960x1471>},\n",
       "     {'type': 'text', 'text': 'original image'},\n",
       "     {'type': 'image',\n",
       "      'image': <PIL.Image.Image image mode=RGB size=960x1471>},\n",
       "     {'type': 'text', 'text': 'mask label: building'},\n",
       "     {'type': 'image',\n",
       "      'image': <PIL.Image.Image image mode=RGB size=960x1471>},\n",
       "     {'type': 'text', 'text': 'mask label: sky'},\n",
       "     {'type': 'image',\n",
       "      'image': <PIL.Image.Image image mode=RGB size=960x1471>},\n",
       "     {'type': 'text', 'text': 'mask label: tower'}]}],\n",
       "  'generated_text': ' The black background is a white silhouette of a gun.'}]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smol_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fdb58f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
